{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b538a16-ae5c-49f0-94dc-8df853ae9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gin\n",
    "import tensorflow as tf\n",
    "from tf_agents.trajectories import trajectory\n",
    "from compiler_opt.rl import agent_config, registry\n",
    "\n",
    "data_path = '/home/student/default_trace'\n",
    "\n",
    "@gin.configurable\n",
    "def train_eval(agent_config_type=agent_config.BCAgentConfig,\n",
    "               num_iterations=100,\n",
    "               batch_size=64,\n",
    "               train_sequence_length=1):\n",
    "    pass\n",
    "\n",
    "gconfig = [\"compiler_opt/rl/inlining/gin_configs/behavioral_cloning_nn_agent.gin\"]\n",
    "gbindings = []\n",
    "gin.parse_config_files_and_bindings(\n",
    "    gconfig, gbindings, skip_unknown=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb2621-1dc5-4dd0-8f52-4276a7aefa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.list_files(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df3aeb8-e5c5-4027-81d7-758df0e55119",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.list_files(data_path)\\\n",
    "    .shuffle(100)\\\n",
    "    .filter(lambda string: tf.strings.length(string) > 0)\\\n",
    "    .apply(tf.data.experimental.shuffle_and_repeat(1024))\\\n",
    "    #.filter(lambda traj: tf.size(traj.reward) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0feb48f-e15f-4c6a-b310-f5f85b034d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_config = registry.get_configuration()\n",
    "time_step_spec, action_spec = problem_config.get_signature_spec()\n",
    "\n",
    "agent_cfg = agent_config.BCAgentConfig(\n",
    "    time_step_spec=time_step_spec,\n",
    "    action_spec=action_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d98a7e-f208-4ea7-947c-66cabf40c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parser_fn(\n",
    "    agent_cfg: agent_config.AgentConfig\n",
    "):\n",
    "  \"\"\"Create a parser function for reading from a serialized tf.SequenceExample.\n",
    "\n",
    "  Args:\n",
    "    agent_name: AgentName, enum type of the agent.\n",
    "    time_step_spec: time step spec of the optimization problem.\n",
    "    action_spec: action spec of the optimization problem.\n",
    "\n",
    "  Returns:\n",
    "    A callable that takes scalar serialized proto Tensors and emits\n",
    "    `Trajectory` objects containing parsed tensors.\n",
    "  \"\"\"\n",
    "\n",
    "  def _parser_fn(serialized_proto):\n",
    "    \"\"\"Helper function that is returned by create_`parser_fn`.\"\"\"\n",
    "    # We copy through all context features at each frame, so even though we know\n",
    "    # they don't change from frame to frame, they are still sequence features\n",
    "    # and stored in the feature list.\n",
    "    context_features = {}\n",
    "    # pylint: disable=g-complex-comprehension\n",
    "    sequence_features = dict(\n",
    "        (tensor_spec.name,\n",
    "         tf.io.FixedLenSequenceFeature(\n",
    "             shape=tensor_spec.shape, dtype=tensor_spec.dtype))\n",
    "        for tensor_spec in agent_cfg.time_step_spec.observation.values())\n",
    "    sequence_features[\n",
    "        agent_cfg.action_spec.name] = tf.io.FixedLenSequenceFeature(\n",
    "            shape=agent_cfg.action_spec.shape,\n",
    "            dtype=agent_cfg.action_spec.dtype)\n",
    "    sequence_features[\n",
    "        agent_cfg.time_step_spec.reward.name] = tf.io.FixedLenSequenceFeature(\n",
    "            shape=agent_cfg.time_step_spec.reward.shape,\n",
    "            dtype=agent_cfg.time_step_spec.reward.dtype)\n",
    "    sequence_features.update(agent_cfg.get_policy_info_parsing_dict())\n",
    "\n",
    "    # pylint: enable=g-complex-comprehension\n",
    "    with tf.name_scope('parse'):\n",
    "      _, parsed_sequence = tf.io.parse_single_sequence_example(\n",
    "          serialized_proto,\n",
    "          context_features=context_features,\n",
    "          sequence_features=sequence_features)\n",
    "      # TODO(yundi): make the transformed reward configurable.\n",
    "      action = parsed_sequence[agent_cfg.action_spec.name]\n",
    "      reward = tf.cast(parsed_sequence[agent_cfg.time_step_spec.reward.name],\n",
    "                       tf.float32)\n",
    "\n",
    "      policy_info = agent_cfg.process_parsed_sequence_and_get_policy_info(\n",
    "          parsed_sequence)\n",
    "\n",
    "      del parsed_sequence[agent_cfg.time_step_spec.reward.name]\n",
    "      del parsed_sequence[agent_cfg.action_spec.name]\n",
    "      full_trajectory = trajectory.from_episode(\n",
    "          observation=parsed_sequence,\n",
    "          action=action,\n",
    "          policy_info=policy_info,\n",
    "          reward=reward)\n",
    "      return full_trajectory\n",
    "\n",
    "  return _parser_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524bca0-ccda-4d8f-80b7-36bb69d2413e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict(\n",
    "        (tensor_spec.name,\n",
    "         tf.io.FixedLenSequenceFeature(\n",
    "             shape=tensor_spec.shape, dtype=tensor_spec.dtype))\n",
    "        for tensor_spec in agent_cfg.time_step_spec.observation.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef27deda-1347-47e1-8bb8-630b38e81602",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.io.FixedLenSequenceFeature(\n",
    "            shape=agent_cfg.action_spec.shape,\n",
    "            dtype=agent_cfg.action_spec.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105bf9a-e68b-42f0-b86b-50f82d59cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_cfg.get_policy_info_parsing_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf093da-97e1-433a-b43a-09e186c72ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_fn = create_parser_fn(agent_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6698f4-8c24-4b6f-b654-9c0a36b2d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.list_files(data_path)\\\n",
    "    .shuffle(100)\\\n",
    "    .interleave(tf.data.TFRecordDataset, cycle_length=10, block_length=1)\\\n",
    "    .filter(lambda string: tf.strings.length(string) > 0)\\\n",
    "    .apply(tf.data.experimental.shuffle_and_repeat(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41c0ae-037d-45ee-b927-dd5b8a93cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = tf.data.Dataset.list_files(data_path)\\\n",
    "    .shuffle(100)\\\n",
    "    .interleave(tf.data.TFRecordDataset, cycle_length=10, block_length=1)\\\n",
    "    .filter(lambda string: tf.strings.length(string) > 0)\\\n",
    "    .apply(tf.data.experimental.shuffle_and_repeat(1024))\n",
    "\n",
    "_iter = iter(foo)\n",
    "for x in range(100):\n",
    "    next(_iter)\n",
    "    print('.', end='')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddc15e-e255-49b7-890a-ce5c630e8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto = next(_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9250f5-74df-4ac3-93d2-3d80ea22c945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "context_features = {}\n",
    "# pylint: disable=g-complex-comprehension\n",
    "sequence_features = dict(\n",
    "    (tensor_spec.name,\n",
    "     tf.io.FixedLenSequenceFeature(\n",
    "         shape=tensor_spec.shape, dtype=tensor_spec.dtype))\n",
    "    for tensor_spec in agent_cfg.time_step_spec.observation.values())\n",
    "sequence_features[\n",
    "    agent_cfg.action_spec.name] = tf.io.FixedLenSequenceFeature(\n",
    "        shape=agent_cfg.action_spec.shape,\n",
    "        dtype=agent_cfg.action_spec.dtype)\n",
    "sequence_features[\n",
    "    agent_cfg.time_step_spec.reward.name] = tf.io.FixedLenSequenceFeature(\n",
    "        shape=agent_cfg.time_step_spec.reward.shape,\n",
    "        dtype=agent_cfg.time_step_spec.reward.dtype)\n",
    "sequence_features.update(agent_cfg.get_policy_info_parsing_dict())\n",
    "\n",
    "#sequence_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92306257-0056-4b83-bf6f-146231bf1913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: enable=g-complex-comprehension\n",
    "with tf.name_scope('parse'):\n",
    "  _, parsed_sequence = tf.io.parse_single_sequence_example(\n",
    "      proto,\n",
    "      context_features=context_features,\n",
    "      sequence_features=sequence_features)\n",
    "  # TODO(yundi): make the transformed reward configurable.\n",
    "  action = parsed_sequence[agent_cfg.action_spec.name]\n",
    "  reward = tf.cast(parsed_sequence[agent_cfg.time_step_spec.reward.name],\n",
    "                   tf.float32)\n",
    "\n",
    "  policy_info = agent_cfg.process_parsed_sequence_and_get_policy_info(\n",
    "      parsed_sequence)\n",
    "\n",
    "  del parsed_sequence[agent_cfg.time_step_spec.reward.name]\n",
    "  del parsed_sequence[agent_cfg.action_spec.name]\n",
    "  full_trajectory = trajectory.from_episode(\n",
    "      observation=parsed_sequence,\n",
    "      action=action,\n",
    "      policy_info=policy_info,\n",
    "      reward=reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93dbb0f-9c03-47df-94df-418164f3cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trajectory.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e674e-3fbb-4759-bf1f-69f13ddcab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "while tf.size(full_trajectory.reward) <= 2 and cnt < 1024:\n",
    "    print('.', end='')\n",
    "    proto = next(_iter)\n",
    "    # pylint: enable=g-complex-comprehension\n",
    "    with tf.name_scope('parse'):\n",
    "      _, parsed_sequence = tf.io.parse_single_sequence_example(\n",
    "          proto,\n",
    "          context_features=context_features,\n",
    "          sequence_features=sequence_features)\n",
    "      # TODO(yundi): make the transformed reward configurable.\n",
    "      action = parsed_sequence[agent_cfg.action_spec.name]\n",
    "      reward = tf.cast(parsed_sequence[agent_cfg.time_step_spec.reward.name],\n",
    "                       tf.float32)\n",
    "    \n",
    "      policy_info = agent_cfg.process_parsed_sequence_and_get_policy_info(\n",
    "          parsed_sequence)\n",
    "    \n",
    "      del parsed_sequence[agent_cfg.time_step_spec.reward.name]\n",
    "      del parsed_sequence[agent_cfg.action_spec.name]\n",
    "      full_trajectory = trajectory.from_episode(\n",
    "          observation=parsed_sequence,\n",
    "          action=action,\n",
    "          policy_info=policy_info,\n",
    "          reward=reward)\n",
    "      cnt += 1\n",
    "print()\n",
    "\n",
    "if tf.size(full_trajectory.reward) > 2:\n",
    "    print(\"Found one!\")\n",
    "else:\n",
    "    print(\"No luck buckaroo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48cd6b4-2f55-4248-b94b-1a2e9f727f90",
   "metadata": {},
   "source": [
    "Theory: Infinite dataset, so it'll just keep looping until it finds a sample that is valid but it never does b/c there are no with size of reward > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6f926-eef5-44a3-bfcd-49bb081cbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto = next(_iter)\n",
    "# pylint: enable=g-complex-comprehension\n",
    "with tf.name_scope('parse'):\n",
    "  _, parsed_sequence = tf.io.parse_single_sequence_example(\n",
    "      proto,\n",
    "      context_features=context_features,\n",
    "      sequence_features=sequence_features)\n",
    "  # TODO(yundi): make the transformed reward configurable.\n",
    "  action = parsed_sequence[agent_cfg.action_spec.name]\n",
    "  reward = tf.cast(parsed_sequence[agent_cfg.time_step_spec.reward.name],\n",
    "                   tf.float32)\n",
    "\n",
    "  policy_info = agent_cfg.process_parsed_sequence_and_get_policy_info(\n",
    "      parsed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458ac84-0dc0-4d0b-929e-9209ed46bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5302f9-066b-4392-9c72-82e96dac8755",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1aeabbb-757f-4b4e-92ea-bb4c3ff6a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e9eff-9ac3-4e9b-8f27-b8e289acee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_cfg.time_step_spec.reward.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db8d37-5fd9-494d-97a4-ec1905d2b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trajectory = trajectory.from_episode(\n",
    "  observation=parsed_sequence,\n",
    "  action=action,\n",
    "  policy_info=policy_info,\n",
    "  reward=reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a6821-a44b-4048-8b09-1a316828c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948db06-0523-4fe8-8a5a-16d4acdc810d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32635e-d43d-457f-b04f-97f65a0cfb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.data.Dataset.list_files(data_path)\\\n",
    "    .shuffle(100)\\\n",
    "    .interleave(tf.data.TFRecordDataset, cycle_length=10, block_length=1)\\\n",
    "    .filter(lambda string: tf.strings.length(string) > 0)\\\n",
    "    .apply(tf.data.experimental.shuffle_and_repeat(1024))\\\n",
    "    .map(parser_fn, num_parallel_calls=8)\\\n",
    "    #.filter(lambda traj: tf.size(traj.reward) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2a50f-3c83-432d-8975-bd9441c980bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3990f6-5b26-4634-96b7-0176f79cad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.cardinality(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684ed30-d1fe-49db-aca6-7655a603fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = (d.unbatch()\\\n",
    "      .batch(\n",
    "        16, # arbitrary number for now\n",
    "        drop_remainder=True)\\\n",
    "      .shuffle(1024)\\\n",
    "      .batch(16, drop_remainder=True)\\\n",
    "      .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a8fe9-9530-4f7c-9fb4-f6f598cdfd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46a3da-9076-482b-a811-f55dec62ffe3",
   "metadata": {},
   "source": [
    "This next cell is the killer :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f449b-8038-4be2-92af-f894658d06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493cf55-861a-4f86-9136-068f0b87db93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
